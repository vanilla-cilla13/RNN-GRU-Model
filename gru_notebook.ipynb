{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64509ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "from dateutil import parser as dateutil_parser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def safe_parse_timestamp(x):\n",
    "    if isinstance(x, pd.Timestamp):\n",
    "        return x.tz_convert('UTC') if x.tzinfo else x.tz_localize('UTC')\n",
    "    try:\n",
    "        ts = pd.to_datetime(x, utc=True, infer_datetime_format=True)\n",
    "        if pd.isna(ts):\n",
    "            raise ValueError()\n",
    "        return ts\n",
    "    except:\n",
    "        dt = dateutil_parser.parse(x)\n",
    "        ts = pd.Timestamp(dt)\n",
    "        if ts.tzinfo is None:\n",
    "            ts = ts.tz_localize('UTC')\n",
    "        else:\n",
    "            ts = ts.tz_convert('UTC')\n",
    "        return ts\n",
    "\n",
    "def extract_segments_from_gt(gt_json):\n",
    "    segs = gt_json.get('segments', gt_json)\n",
    "    out=[]\n",
    "    for s in segs:\n",
    "        start = safe_parse_timestamp(s['start'])\n",
    "        end   = safe_parse_timestamp(s['end'])\n",
    "        label = s.get('label',0)\n",
    "        out.append({'start':start,'end':end,'label':label})\n",
    "    return out\n",
    "\n",
    "def labels_from_segments(timestamps, segments, fill_label=0):\n",
    "    ts = pd.to_datetime(timestamps, utc=True)\n",
    "    labels = np.full(len(ts), fill_label, dtype=object)\n",
    "    for seg in segments:\n",
    "        mask = (ts>=seg['start']) & (ts<seg['end'])\n",
    "        labels[mask]=seg['label']\n",
    "    uniq=[u for u in np.unique(labels) if u!=fill_label]\n",
    "    label_map={lbl:i+1 for i,lbl in enumerate(uniq)}\n",
    "    label_map[fill_label]=0\n",
    "    int_labels=np.array([label_map.get(l,0) for l in labels])\n",
    "    return int_labels, label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"table_task_UR5e_data.csv\")\n",
    "GT_PATH   = Path(\"table_task_UR5e_ground_truth.json\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64021e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GT_PATH, \"r\") as f:\n",
    "    gt = json.load(f)\n",
    "\n",
    "segments = []\n",
    "for seg_name, seg_info in gt.items():\n",
    "    segments.append({\n",
    "        \"label\": seg_info[\"label_id\"],\n",
    "        \"start\": pd.to_datetime(seg_info[\"start\"], errors=\"coerce\"),\n",
    "        \"end\":   pd.to_datetime(seg_info[\"end\"],   errors=\"coerce\")\n",
    "    })\n",
    "\n",
    "segments[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(len(df), dtype=int)\n",
    "\n",
    "for seg in segments:\n",
    "    mask = (df[\"timestamp\"] >= seg[\"start\"]) & (df[\"timestamp\"] <= seg[\"end\"])\n",
    "    labels[mask] = seg[\"label\"]\n",
    "\n",
    "df[\"label\"] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"x\", \"y\", \"z\"]\n",
    "X = df[features].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b4e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 50\n",
    "\n",
    "def make_sequences(X, y, seq_len=SEQ_LEN):\n",
    "    X_out, y_out = [], []\n",
    "    for i in range(0, len(X)-seq_len):\n",
    "        X_out.append(X[i:i+seq_len])\n",
    "        y_out.append(y[i:i+seq_len])\n",
    "    return X_out, y_out\n",
    "\n",
    "X_seq, y_seq = make_sequences(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33081adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * len(X_seq))\n",
    "\n",
    "X_train = X_seq[:split]\n",
    "y_train = y_seq[:split]\n",
    "\n",
    "X_test  = X_seq[split:]\n",
    "y_test  = y_seq[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(X, y):\n",
    "    max_len = max(len(seq) for seq in X)\n",
    "\n",
    "    X_pad, y_pad = [], []\n",
    "    for seq, labels in zip(X, y):\n",
    "        pad_len = max_len - len(seq)\n",
    "\n",
    "        seq_pad = np.pad(seq, ((0, pad_len), (0, 0)), mode='constant')\n",
    "        lab_pad = np.pad(labels, (0, pad_len), mode='constant')\n",
    "\n",
    "        X_pad.append(seq_pad)\n",
    "        y_pad.append(lab_pad)\n",
    "\n",
    "    return np.array(X_pad), np.array(y_pad)\n",
    "\n",
    "X_train_pad, y_train_pad = pad_sequences(X_train, y_train)\n",
    "X_test_pad,  y_test_pad  = pad_sequences(X_test,  y_test)\n",
    "\n",
    "X_train_t = torch.tensor(X_train_pad, dtype=torch.float32).to(device)\n",
    "y_train_t = torch.tensor(y_train_pad, dtype=torch.long).to(device)\n",
    "X_test_t  = torch.tensor(X_test_pad,  dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUSegmenter(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_t.shape[2]\n",
    "hidden_dim = 64\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "model = GRUSegmenter(input_dim, hidden_dim, num_classes).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(X_train_t)\n",
    "    loss = criterion(\n",
    "        outputs.reshape(-1, num_classes),\n",
    "        y_train_t.reshape(-1)\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_t)\n",
    "    y_pred_pad = logits.argmax(dim=2).cpu().numpy()\n",
    "\n",
    "# unpad\n",
    "y_pred = []\n",
    "for pred_seq, true_seq in zip(y_pred_pad, y_test):\n",
    "    y_pred.append(pred_seq[:len(true_seq)])\n",
    "\n",
    "len(y_pred), len(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(y_test[0], label=\"True\", linewidth=2)\n",
    "plt.plot(y_pred[0], label=\"Predicted\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"Example Sequence â€” True vs Predicted Labels\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_flat = np.concatenate(y_pred)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(y, label=\"Ground Truth\")\n",
    "plt.plot(range(len(y_pred_flat)), y_pred_flat, label=\"RNN Predicted\", alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title(\"Full-Timeline Segmentation\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
